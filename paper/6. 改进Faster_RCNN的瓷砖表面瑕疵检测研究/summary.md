## Summary改进Faster R-CNN算法
**文章提出了一种改进的 Faster RCNN 算法，针对瓷砖表面瑕疵中存在的极小瑕疵目标、瑕疵形态差异大、易漏检和准确率低等问题。**   
### 改进：
文章从三个方面改进了 Faster RCNN 算法：**网络结构、区域建议网络、损失函数**。   
#### 网络结构
文章在 Faster RCNN 的特征提取网络 ResNet101 的后三个阶段引入了可变形卷积网络。可变形卷积网络可以根据瑕疵目标的形状自适应地调整卷积核的形状，并学习更多的瑕疵特征。   
- **可变形卷积网络**是一种新型的卷积，它可以通过学习每个采样点在卷积核中的偏移量，来适应目标的形状和姿态。它可以捕获比普通卷积更细粒度和不规则的目标特征。可变形卷积网络被引入到 ResNet101 的后三个阶段中，替换了标准的 3x3 卷积。
   
**why?**
- 原来的网络结构中使用的是标准的卷积层，这种卷积层只能处理规则的矩形区域，而瓷砖表面的瑕疵可能有各种不同的形状和大小，因此需要一种能够适应不同形状目标的卷积层。
- 原来的网络结构中使用的是交叉熵损失函数，这种损失函数只能区分正负样本，而不能区分正样本之间的质量差异，也不能解决类别不平衡问题，因此需要一种能够考虑正样本之间排序和类别平衡的损失函数。   
     
*** 
#### 区域建议网络（RPN）
文章通过分析瓷砖瑕疵数据集，优化了锚点生成参数。文章增加了两种长宽比（0.2 和 5）并去掉了两种缩放比例（16 和 32）来生成锚框。文章声称这些参数可以更好地匹配瑕疵目标尺度，检测窄长的瑕疵和小的瑕疵。   
   
**why?**
- 原来的RPN中生成的锚框的大小和比例对候选区域生成部分有着十分重要的影响，**合适的锚框可以更多地检测出待测目标**，若锚框大小和目标大小相差较大，会使生成的候选区域不准确，从而严重影响模型性能和检测效果。
- 原来的RPN中以[ 0.5，1，2 ]三种长宽比和[ 8，16，32 ]三种缩放比例组合生成一组锚框，即一组由9个 anchor boxs 组成。但是对于瓷砖表面瑕疵检测而言，数据集中存在 8 个像素左右的**小目标**，以及**长宽比差异较大**的瑕疵目标，由此可得原始生成锚框的尺度不能很好地匹配瓷砖表面瑕疵数据集中所检测的目标尺度。
***
#### 损失函数
文章使用了 Rank & Sort 损失来替代原始 Faster RCNN 的损失函数。Rank & Sort 损失是一种基于排序的损失函数，可以简化模型训练的复杂性，减少参数数量。它还可以通过根据置信度分数对正样本进行排序，并在训练中给予它们不同的优先级，来处理类别不平衡问题。   
   
**why?**
- 原来的损失函数是交叉熵损失函数，这种损失函数只能区分正负样本，而不能区分正样本之间的质量差异，也不能解决类别不平衡问题，因此需要一种能够考虑正样本之间排序和类别平衡的损失函数。
- 原来的损失函数是基于二值标签的，即正样本为1，负样本为0，这种标签不能反映出正样本与真实框之间的交并比IoU，也不能反映出正样本之间的相对质量，因此需要一种能够使用连续标签的损失函数。
   
Rank & Sort Loss的计算过程主要分为以下几步：
- 首先，根据Faster RCNN模型边界框回归输出的预测框，求出预测框和真实框之间的交并比IoU，记为y，再将Faster RCNN模型分类回归输出的分类得分s和y共同作为Rank & Sort Loss的输入。
- 其次，根据以下公式依次计算出当前ranking误差R(i)，当前sorting误差S(i)，目标ranking误差R(i)，目标sorting误差S(i)。
- 然后，将当前ranking误差与目标sorting误差相减即得到ranking Loss，R(i)-R(i)，将当前sorting误差与目标sorting误差相减即得到sorting Loss，S(i)-S(i)，将两者相加即得到总损失，R(i)+S(i)-R(i)-S(i)。
- 最后，将上述求得的总损失除以正样本总数即可得到Rank & Sort Loss。
