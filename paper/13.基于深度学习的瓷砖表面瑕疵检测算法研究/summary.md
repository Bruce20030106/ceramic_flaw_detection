## 改进YOLOv5s 
这篇论文中的模型效果最好的是基于改进 YOLOv5s 的瓷砖表面瑕疵检测算法，它在准确率、F1 和 mAP 值上都超过了其他模型，如 VGG16-SSD、YOLOv3、YOLOv4、YOLOv5m。以下主要对改进方法做出总结。
### 改进YOLOv5s的方法：
#### 加深主干网络
1. 加深主干网络的好处是可以提取更小目标的特征，使模型学习到的特征更加全面。
2. 主干网络是目标检测模型中用于提取基本特征的部分，通常采用预训练的分类网络作为主干网络。
3. 由于瓷砖瑕疵检测中存在高分辨率图像下的小目标瑕疵问题，加深主干网络可以增强模型对小目标的感知能力，提高检测精度。
4. 具体做法是：在主干网络中增加一个 3×3×1536 的卷积层和一个通道数为 1536 的 C3 层
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/backbone.jpg?raw=true)
#### 在颈部网络中重新融合不同尺度的特征图
1. 好处：增强上下层特征的融合能力，提高检测精度。因为低卷积层获取信息多，但噪声多，提取的特征不够；高卷积层特征明显，但随着分辨率降低，小目标的特征可能会丢失
2. 具体做法：先在颈部网络中添加一个完整特征融合模块，包括卷积层(卷积核为 3×3)、上采样层、Concat 层和 C3 层
3. 具体做法：针对数据集中存在的小目标瑕疵，增加一个16×16的小尺寸检测层，网络模型由3输出预测层增加为4输出预测层。
4. 预测层是 YOLOv5 网络结构中的最后一部分，用于对不同尺度的特征图进行目标检测和分类
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84.jpg?raw=true)
#### 在模型中添加注意力机制模块
- 注意力机制就是聚焦图像的局部信息，使算法模型更加关注图像的特定区域，更有可能识别出目标的细节；自适应的学习权重，降低无关特征信息的干扰。
- **通道注意力机制**：图像转换为feature map（特征图）后，只有部分区域有检测目标，我们希望在这些部分增加权重，以便更好地获取特征
- 该模块根据图像背景的不同，增加或者抑制瓷砖瑕疵不同通道特征图的权重，自适应学习各个通道的重要程度以提高检测精度。
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E6%B3%A8%E6%84%8F%E5%8A%9B.jpg?raw=true)
- **空间注意力机制**：空间注意力机制就是寻找网络中最重要的部位进行处理，空间注意力通过学习输入图像或特征图的形变，完成适合任务的预处理操作
- 空间注意力共包括 3 个模块，分别是定位网络、网格生成器和采样器：  
    
1. **定位网络**：这个模块的作用是根据输入图像或特征图学习一个空间变换的参数，例如仿射变换、投影变换或者薄板样条变换。这些参数可以控制图像的平移、缩放、旋转或者更复杂的变形。定位网络可以是任意的可微分网络，例如卷积神经网络或者全连接网络。   
   
2. **网格生成器**：这个模块的作用是根据定位网络输出的变换参数，生成一个与输入图像或特征图相同大小的网格。每个网格点对应于输入图像或特征图上的一个像素位置。网格生成器通过应用变换参数到原始网格上，得到一个变换后的网格，反映了图像或特征图经过空间变换后的位置关系。   
   
3. **采样器**：这个模块的作用是根据变换后的网格和输入图像或特征图，生成一个输出图像或特征图。采样器通过在输入图像或特征图上进行双线性插值，来估计变换后网格点对应的像素值。采样器保证了空间变换的可微分性，使得整个空间注意力网络可以通过反向传播进行训练。   
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E6%B3%A8%E6%84%8F%E5%8A%9B2.jpg?raw=true)   
- **混合注意力机制**：通道注意力更加注重的是目标的类别信息，缺少对位置信息的检测能力；而空间注意力更加注重目标的位置信息，缺乏对目标类别的判断能力,我们希望把二者融合
- 具体做法及其公式详见论文
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E6%B3%A8%E6%84%8F%E5%8A%9B3.jpg?raw=true)
#### 轻量化模型
- **利用深度可分离卷积替换原始卷积模块**在不影响检测精度的情况下，降低模型的参数量和计算量，提高检测速度。
- 深度可分离卷积通过深度卷积和点卷积两步操作完成卷积过程，
1. 第一步是深度卷积，首先将多通道的特征图拆分为单一通道，然后使用 3×3×1 的卷积核对单一通道进行卷积，只改变特征图的尺寸，卷积完成后对其叠加；
2. 第二步是点卷积，这里使用的卷积都是 1×1，只改变通道数，而不影响特征图的尺寸
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF.jpg?raw=true)
![](https://github.com/OctoberEnd/verbose-invention/blob/main/pic/%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF.jpg?raw=true)
![网页介绍深度可分离卷积](https://paperswithcode.com/method/depthwise-separable-convolution)
