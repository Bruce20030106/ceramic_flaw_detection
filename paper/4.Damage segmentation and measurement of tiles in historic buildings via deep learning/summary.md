# 故宫瓦片图像的自动裁剪和检测
**总结：论文提出了一种基于深度学习技术的两级策略，实现了对历史建筑屋顶上的琉璃瓦的自动损伤检测、分割和测量的方法。首次使用两级策略基于深度学习自动检测、分割和测量历史建筑上的大规模表面损伤。**
1. 第一级利用Faster R-CNN方法从屋顶图像中自动检测和裁剪两种类型的琉璃瓦，并将裁剪后的图像用于训练Mask R-CNN模型。
2. 第二级利用Mask R-CNN方法对裁剪后的琉璃瓦图像进行损伤分割和测量，并基于Mask R-CNN的预测结果定量评估损伤的形态特征，如损伤拓扑、面积和比例。
***
## Model Training
### Faster R-CNN是如何训练的
Faster R-CNN包含两个核心组件——区域提议网络（RPN）和Fast R-CNN。RPN和Fast R-CNN网络都使用相同的CNN从原始图像中提取特征。   
   
论文中的Faster R-CNN模型是使用ZF-Net作为CNN来提取特征，然后使用RPN来生成候选区域，最后使用全连接层来输出瓦片的类别和边界框。
   
全连接层是指神经网络中的一种层，它由权重、偏置和神经元组成，用于将两个不同层的神经元完全连接起来。全连接层通常放在输出层之前，构成CNN架构的最后几层。全连接层的作用是利用卷积过程中提取的特征，来预测图像的类别或其他信息。在论文中，全连接层是用来输出瓦片的类别和边界框的。  
   
在RPN中，使用了一种叫做**锚点anchor**的概念来生成候选区域。锚点实际上就是一些固定大小和宽高比的矩形框，它们被放置在输入图像的每个位置上，并作为可能包含目标的候选区域。这些锚点的大小和宽高比通常是预先定义好的，例如在Faster R-CNN中，使用了三种不同的尺度和三种不同的宽高比，共计九种锚点。在RPN中，每个锚点都会输出两个分数，表示它是前景（即包含目标）和背景（即不包含目标）的概率。通过对这些锚点进行非极大值抑制（NMS）操作，就可以得到最终的候选区域。   
***
### Mask R-CNN是如何训练的
论文中的Mask R-CNN是使用ResNet101和FPN作为CNN来提取特征，然后使用RPN来生成候选区域，最后使用ROI align和全连接层来输出瓦片的类别、边界框和分割掩码。   
   
论文中使用了多任务损失函数来训练Mask R-CNN模型，包括分类损失、边界框回归损失和分割损失。为了训练这个模型，定义一个合适的损失函数，来衡量预测结果和真实标签之间的差异。   
   
**ROI**是Region of Interest的缩写，意思是**感兴趣区域**。在计算机视觉中，ROI通常指的是图像中包含有用信息的一部分，例如目标对象的边界框或分割掩码。在论文中，ROI代表的是瓦片图像中的损伤区域，也就是Mask R-CNN要分割和测量的对象。   
  
**掩码分支**是指Mask R-CNN模型中的一个分支，它用于对每个候选区域进行像素级的分割，输出K×m×m的二值掩码，其中K是类别数，m是掩码的大小。掩码分支是一个全卷积网络，它使用ROI align层来提取每个候选区域的特征图，然后使用几个卷积层和反卷积层来生成掩码。掩码分支只对正样本（与真实边界框的IoU大于0.5的候选区域）有效，且只输出与预测类别标签一致的Ki类别的掩码。最终，所有预测的掩码可以用来表示损伤区域的形状和位置。   
   
掩码分支中的**掩码**是指一个二值矩阵，它表示一个候选区域中的哪些像素属于某个类别，哪些像素不属于。掩码中的1表示属于该类别的像素，0表示不属于该类别的像素。例如，对于瓦片的损伤分割，掩码中的1表示损伤区域的像素，0表示正常区域的像素。掩码可以用来可视化分割结果，也可以用来计算损伤的面积和比例。
